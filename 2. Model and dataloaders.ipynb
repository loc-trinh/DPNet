{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model import create_dpnet_one\n",
    "model = create_dpnet_one(in_channel=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand((5,18,256,256))\n",
    "outputs = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torchvision import transforms\n",
    "from model import dataloader\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "data_dir = '/meladyfs/newyork/loctrinh/DATASETS/'\n",
    "frame_count = {'FF++': pd.read_csv(os.path.join(data_dir, 'FF++', 'video_stat.csv'), index_col=0)}\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'FF++/splits/{}_trainlist_01.csv'.format('Deepfakes')))\n",
    "val_df = pd.read_csv(os.path.join(data_dir, 'FF++/splits/{}_vallist_01.csv'.format('Deepfakes')))\n",
    "test_df = pd.read_csv(os.path.join(data_dir, 'FF++/splits/{}_testlist_01.csv'.format('Deepfakes')))\n",
    "\n",
    "data_loader = dataloader.StackNImageLoader(10, 2, data_dir, frame_count, train_df, val_df, test_df, train_transform, test_transform)\n",
    "train_loader, val_loader, test_loader, push_loader = data_loader.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.39 s ± 344 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "imgs, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name, frame_index, imgs, labels = next(iter(push_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from PIL import Image\n",
    "idx = 3\n",
    "print(labels[idx])\n",
    "unform = UnNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "display(Image.fromarray(tensor2uint8(unform(imgs[idx][:3]))))\n",
    "display(Image.fromarray(tensor2uint8(imgs[idx][4:5])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
