{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from model import dataloader\n",
    "from model import create_dpnet\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from sklearn.metrics import make_scorer, roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def calculate_eer(y_true, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    return eer\n",
    "    \n",
    "class DPNet():\n",
    "    def __init__(self, device, log_dir, args, train_loader, val_loader, test_loader):\n",
    "        self.device = device\n",
    "        self.log_dir = log_dir\n",
    "        self.args = args\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader   = val_loader\n",
    "        self.test_loader  = test_loader\n",
    "        \n",
    "        self.best_val_auc = 0\n",
    "        self.counter = 0\n",
    "        self.patience = 5\n",
    "        \n",
    "        self.build_model()\n",
    "        \n",
    "    def build_model(self):        \n",
    "        self.model = create_dpnet(in_channel=3)\n",
    "        self.model = nn.DataParallel(self.model)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        if self.args.checkpoint:\n",
    "            cp = torch.load(self.args.checkpoint)\n",
    "            self.epoch = cp['epoch']\n",
    "            self.model.load_state_dict(cp['state_dict'])\n",
    "\n",
    "        self.model = self.model.to(self.device)  \n",
    "        \n",
    "    def test(self):\n",
    "        self.validate_1epoch(test_mode=True)\n",
    "\n",
    "    def validate_1epoch(self, test_mode = False):\n",
    "        if test_mode:\n",
    "            print('|--> [testing stage]')\n",
    "        else:\n",
    "            print('|--> Epoch:[{0}/{1}][validation stage]'.format(self.epoch+1, self.args.num_epochs))\n",
    "\n",
    "        losses, top1 = AverageMeter(), AverageMeter()\n",
    "\n",
    "        # Evaluate mode\n",
    "        self.model.eval()\n",
    "        self.dic_video_level_preds = {}\n",
    "        \n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            progress = tqdm(self.test_loader) if test_mode else tqdm(self.val_loader)\n",
    "            for _, (video_names, inputs, labels) in enumerate(progress):\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                # Compute output\n",
    "                batch_size = inputs.shape[0]             \n",
    "                outputs, min_distances = self.model(inputs)\n",
    "\n",
    "                # Accumulate video level prediction\n",
    "                preds = outputs.data.cpu().numpy()\n",
    "                for i in range(batch_size):\n",
    "                    video_name = video_names[i]\n",
    "                    if video_name not in self.dic_video_level_preds.keys():\n",
    "                        self.dic_video_level_preds[video_name] = preds[i,:]\n",
    "                    else:\n",
    "                        self.dic_video_level_preds[video_name] += preds[i,:]\n",
    "        \n",
    "        # Calculate video level statistics\n",
    "        video_top1, video_auc, video_loss, video_pauc_10, video_eer = self.frame_2_video_level_accuracy()\n",
    "\n",
    "        info = {'Epoch': [self.epoch],\n",
    "                'Time':  [round(time.time()-start,3)],\n",
    "                'Loss':  [round(video_loss,5)],\n",
    "                'Acc':   [round(video_top1,4)],\n",
    "                'AUC':   [round(video_auc,4)],\n",
    "                'pAUC_10':    [round(video_pauc_10,4)],\n",
    "                'EER':   [round(video_eer,4)]}\n",
    "        if test_mode:\n",
    "            print(info)\n",
    "        else:\n",
    "            record_info(info, os.path.join(self.log_dir, 'test.csv'))\n",
    "        return video_top1, video_auc, video_loss\n",
    "                             \n",
    "    def frame_2_video_level_accuracy(self):\n",
    "        correct = 0\n",
    "        video_level_preds = np.zeros((len(self.dic_video_level_preds),2))\n",
    "        video_level_labels = np.zeros(len(self.dic_video_level_preds))\n",
    "        \n",
    "        for i, name in enumerate(sorted(self.dic_video_level_preds.keys())):\n",
    "            preds = self.dic_video_level_preds[name]\n",
    "            label = 1.0 if 'FAKE' in name else 0.0\n",
    "                \n",
    "            video_level_preds[i,:] = preds / 100\n",
    "            video_level_labels[i] = label\n",
    "            if np.argmax(preds) == (label):\n",
    "                correct += 1\n",
    "        if self.args.save_predictions:         \n",
    "            np.save(open(f'predictions/{self.args.start_task}_{self.args.task}_labels_{self.args.stream}.npy','wb'), video_level_labels)\n",
    "            np.save(open(f'predictions/{self.args.start_task}_{self.args.task}_preds_{self.args.stream}.npy','wb'), video_level_preds)\n",
    "\n",
    "        video_level_labels = torch.from_numpy(video_level_labels).long()\n",
    "        video_level_preds = torch.from_numpy(video_level_preds).float()\n",
    "            \n",
    "        top1 = accuracy(video_level_preds, video_level_labels, topk=(1,))\n",
    "        loss = self.criterion(video_level_preds, video_level_labels)\n",
    "                                 \n",
    "        logits = nn.functional.softmax(video_level_preds, dim=1)[:, 1].numpy()\n",
    "        auc = roc_auc_score(video_level_labels, logits)\n",
    "        pauc_10 = roc_auc_score(video_level_labels, logits, max_fpr=0.1)\n",
    "        eer = calculate_eer(video_level_labels, logits)\n",
    "        \n",
    "        return top1.item(), auc, loss.item(), pauc_10, eer                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepfakes to Deepfakes\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:46<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [166.137], 'Loss': [0.01319], 'Acc': [99.2857], 'AUC': [0.9999], 'pAUC_10': [0.9995], 'EER': [0.014]}\n",
      "Deepfakes to Face2Face\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:54<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [174.602], 'Loss': [4.50846], 'Acc': [52.1429], 'AUC': [0.8024], 'pAUC_10': [0.598], 'EER': [0.2657]}\n",
      "Deepfakes to FaceSwap\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:57<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [177.525], 'Loss': [11.47503], 'Acc': [49.6429], 'AUC': [0.279], 'pAUC_10': [0.4753], 'EER': [0.6571]}\n",
      "Deepfakes to NeuralTextures\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:59<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [179.285], 'Loss': [2.904], 'Acc': [58.2143], 'AUC': [0.8765], 'pAUC_10': [0.7081], 'EER': [0.1643]}\n",
      "Deepfakes to FF++\n",
      "==> Training data: 972000 frames\n",
      "==> Validation data: 70000 frames\n",
      "==> Testing data: 70000 frames\n",
      "==> Pushing data: 360000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2188 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2188/2188 [07:35<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [455.352], 'Loss': [7.54921], 'Acc': [44.1429], 'AUC': [0.7395], 'pAUC_10': [0.6952], 'EER': [0.3116]}\n",
      "Face2Face to Deepfakes\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:58<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [178.642], 'Loss': [3.6989], 'Acc': [50.3571], 'AUC': [0.8223], 'pAUC_10': [0.6485], 'EER': [0.2571]}\n",
      "Face2Face to Face2Face\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:59<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [179.335], 'Loss': [0.06816], 'Acc': [99.2857], 'AUC': [0.9952], 'pAUC_10': [0.9925], 'EER': [0.0143]}\n",
      "Face2Face to FaceSwap\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:59<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [179.401], 'Loss': [5.01213], 'Acc': [50.0], 'AUC': [0.4766], 'pAUC_10': [0.4946], 'EER': [0.5286]}\n",
      "Face2Face to NeuralTextures\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:59<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [179.24], 'Loss': [4.16911], 'Acc': [50.0], 'AUC': [0.7223], 'pAUC_10': [0.5897], 'EER': [0.3429]}\n",
      "Face2Face to FF++\n",
      "==> Training data: 972000 frames\n",
      "==> Validation data: 70000 frames\n",
      "==> Testing data: 70000 frames\n",
      "==> Pushing data: 360000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2188 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2188/2188 [07:36<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [456.205], 'Loss': [5.17916], 'Acc': [39.8571], 'AUC': [0.7541], 'pAUC_10': [0.6813], 'EER': [0.3143]}\n",
      "FaceSwap to Deepfakes\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:59<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [1], 'Time': [179.245], 'Loss': [9.28957], 'Acc': [50.0], 'AUC': [0.537], 'pAUC_10': [0.5405], 'EER': [0.4714]}\n",
      "FaceSwap to Face2Face\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:59<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [1], 'Time': [179.588], 'Loss': [7.51737], 'Acc': [50.0], 'AUC': [0.6975], 'pAUC_10': [0.5902], 'EER': [0.3554]}\n",
      "FaceSwap to FaceSwap\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:59<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [1], 'Time': [179.419], 'Loss': [0.09711], 'Acc': [99.2857], 'AUC': [0.994], 'pAUC_10': [0.9962], 'EER': [0.0071]}\n",
      "FaceSwap to NeuralTextures\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:59<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [1], 'Time': [179.548], 'Loss': [10.88944], 'Acc': [50.0], 'AUC': [0.416], 'pAUC_10': [0.4868], 'EER': [0.5786]}\n",
      "FaceSwap to FF++\n",
      "==> Training data: 972000 frames\n",
      "==> Validation data: 70000 frames\n",
      "==> Testing data: 70000 frames\n",
      "==> Pushing data: 360000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2188 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2188/2188 [07:36<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [1], 'Time': [456.449], 'Loss': [11.11734], 'Acc': [39.7143], 'AUC': [0.6611], 'pAUC_10': [0.6535], 'EER': [0.4]}\n",
      "NeuralTextures to Deepfakes\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:59<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [179.279], 'Loss': [1.30951], 'Acc': [67.5], 'AUC': [0.9072], 'pAUC_10': [0.6955], 'EER': [0.1571]}\n",
      "NeuralTextures to Face2Face\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:59<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [179.794], 'Loss': [3.51625], 'Acc': [53.2143], 'AUC': [0.6924], 'pAUC_10': [0.5454], 'EER': [0.35]}\n",
      "NeuralTextures to FaceSwap\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [03:00<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [180.151], 'Loss': [5.50233], 'Acc': [48.5714], 'AUC': [0.4438], 'pAUC_10': [0.4839], 'EER': [0.5286]}\n",
      "NeuralTextures to NeuralTextures\n",
      "==> Training data: 388800 frames\n",
      "==> Validation data: 28000 frames\n",
      "==> Testing data: 28000 frames\n",
      "==> Pushing data: 144000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [02:59<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [179.435], 'Loss': [0.23931], 'Acc': [95.7143], 'AUC': [0.9818], 'pAUC_10': [0.9637], 'EER': [0.0429]}\n",
      "NeuralTextures to FF++\n",
      "==> Training data: 972000 frames\n",
      "==> Validation data: 70000 frames\n",
      "==> Testing data: 70000 frames\n",
      "==> Pushing data: 360000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2188 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2188/2188 [07:36<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [456.915], 'Loss': [4.13182], 'Acc': [48.5714], 'AUC': [0.7563], 'pAUC_10': [0.6721], 'EER': [0.2995]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures']:\n",
    "    for j in ['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures', 'FF++']:\n",
    "        print(f'{i} to {j}')\n",
    "\n",
    "        class Args:\n",
    "            gpu = '2,3'\n",
    "            start_task = i\n",
    "            task = j\n",
    "            num_workers = 8\n",
    "            num_epochs = 20\n",
    "            batch_size = 32\n",
    "            learning_rate = 2e-4\n",
    "            stream = 'rgb'\n",
    "            checkpoint = ''\n",
    "            save_predictions = False\n",
    "        args = Args()\n",
    "        \n",
    "        if args.stream =='rgb':\n",
    "            args.checkpoint = f'record/{i}/seed_1/best_val_checkpoint.pth'\n",
    "        elif args.stream == 'luminance':\n",
    "            args.checkpoint = f'record/luminance/{i}/seed_1/best_val_checkpoint.pth'\n",
    "        elif args.stream == 'sharpened':\n",
    "            args.checkpoint = f'record/sharpened/{i}/seed_1/best_val_checkpoint.pth'\n",
    "\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        log_dir = ''\n",
    "\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "        data_dir = '/meladyfs/newyork/loctrinh/DATASETS/'\n",
    "        frame_count = {'FF++': pd.read_csv(os.path.join(data_dir, 'FF++', 'video_stat.csv'), index_col=0)}\n",
    "        train_df = pd.read_csv(os.path.join(data_dir, '{}/splits/{}_trainlist_01.csv'.format('FF++', args.task)))\n",
    "        val_df = pd.read_csv(os.path.join(data_dir, '{}/splits/{}_vallist_01.csv'.format('FF++', args.task)))\n",
    "        test_df = pd.read_csv(os.path.join(data_dir, '{}/splits/{}_testlist_01.csv'.format('FF++', args.task)))\n",
    "        \n",
    "        if args.stream == 'rgb':\n",
    "            data_loader = dataloader.SingleImageLoader(args.batch_size, args.num_workers, data_dir, frame_count,\n",
    "                                                       train_df, val_df, test_df, train_transform, test_transform)\n",
    "        elif args.stream == 'luminance':\n",
    "            data_loader = dataloader.LuminanceGradientImageLoader(args.batch_size, args.num_workers, data_dir, frame_count,\n",
    "                                                                  train_df, val_df, test_df, train_transform, test_transform)\n",
    "        elif args.stream == 'sharpened':\n",
    "            data_loader = dataloader.SharpenedImageLoader(args.batch_size, args.num_workers, data_dir, frame_count,\n",
    "                                                                  train_df, val_df, test_df, train_transform, test_transform)\n",
    "        \n",
    "        train_loader, val_loader, test_loader, push_loader = data_loader.run()\n",
    "\n",
    "        # =================== Training =================== \n",
    "        detector = DPNet(device=device,\n",
    "                            log_dir=log_dir,\n",
    "                            args=args,\n",
    "                            train_loader=train_loader,\n",
    "                            val_loader=val_loader,\n",
    "                            test_loader=test_loader)\n",
    "        detector.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
