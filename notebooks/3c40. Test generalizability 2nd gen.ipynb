{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from model import dataloader\n",
    "from model import create_dpnet_one\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from sklearn.metrics import make_scorer, roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def calculate_eer(y_true, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    return eer\n",
    "\n",
    "def calculate_tpr_10(y_true, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1, drop_intermediate = False)\n",
    "    idx = 0\n",
    "    for _, i in enumerate(fpr):\n",
    "        if i <= .1: idx = _\n",
    "        else: break\n",
    "    return tpr[idx]\n",
    "    \n",
    "class DPNet():\n",
    "    def __init__(self, device, log_dir, args, train_loader, val_loader, test_loader):\n",
    "        self.device = device\n",
    "        self.log_dir = log_dir\n",
    "        self.args = args\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader   = val_loader\n",
    "        self.test_loader  = test_loader\n",
    "        \n",
    "        self.best_val_auc = 0\n",
    "        self.counter = 0\n",
    "        self.patience = 5\n",
    "        \n",
    "        self.build_model()\n",
    "        \n",
    "    def build_model(self):        \n",
    "        self.model = create_dpnet_one()\n",
    "        self.model = nn.DataParallel(self.model)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        if self.args.checkpoint:\n",
    "            cp = torch.load(self.args.checkpoint)\n",
    "            self.epoch = cp['epoch']\n",
    "            self.model.load_state_dict(cp['state_dict'])\n",
    "\n",
    "        self.model = self.model.to(self.device)  \n",
    "        \n",
    "    def test(self):\n",
    "        self.validate_1epoch(test_mode=True)\n",
    "\n",
    "    def validate_1epoch(self, test_mode = False):\n",
    "        if test_mode:\n",
    "            print('|--> [testing stage]')\n",
    "        else:\n",
    "            print('|--> Epoch:[{0}/{1}][validation stage]'.format(self.epoch+1, self.args.num_epochs))\n",
    "\n",
    "        losses, top1 = AverageMeter(), AverageMeter()\n",
    "\n",
    "        # Evaluate mode\n",
    "        self.model.eval()\n",
    "        self.dic_video_level_preds = {}\n",
    "        \n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            progress = tqdm(self.test_loader) if test_mode else tqdm(self.val_loader)\n",
    "            for _, (video_names, inputs, labels) in enumerate(progress):\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                # Compute output\n",
    "                batch_size = inputs.shape[0]             \n",
    "                outputs, min_distances = self.model(inputs)\n",
    "\n",
    "                # Accumulate video level prediction\n",
    "                preds = outputs.data.cpu().numpy()\n",
    "                for i in range(batch_size):\n",
    "                    video_name = video_names[i]\n",
    "                    if video_name not in self.dic_video_level_preds.keys():\n",
    "                        self.dic_video_level_preds[video_name] = preds[i,:]\n",
    "                    else:\n",
    "                        self.dic_video_level_preds[video_name] += preds[i,:]\n",
    "        \n",
    "        # Calculate video level statistics\n",
    "        video_top1, video_auc, video_loss, video_pauc_10, video_tar_10, video_eer = self.frame_2_video_level_accuracy()\n",
    "\n",
    "        info = {'Epoch': [self.epoch],\n",
    "                'Time':  [round(time.time()-start,3)],\n",
    "                'Loss':  [round(video_loss,5)],\n",
    "                'Acc':   [round(video_top1,4)],\n",
    "                'AUC':   [round(video_auc,4)],\n",
    "                'pAUC_10':    [round(video_pauc_10,4)],\n",
    "                'TAR_10':    [round(video_tar_10,4)],\n",
    "                'EER':   [round(video_eer,4)]}\n",
    "        if test_mode:\n",
    "            print(info)\n",
    "        else:\n",
    "            record_info(info, os.path.join(self.log_dir, 'test.csv'))\n",
    "        return video_top1, video_auc, video_loss\n",
    "                             \n",
    "    def frame_2_video_level_accuracy(self):\n",
    "        correct = 0\n",
    "        video_level_preds = np.zeros((len(self.dic_video_level_preds),2))\n",
    "        video_level_labels = np.zeros(len(self.dic_video_level_preds))\n",
    "        \n",
    "        for i, name in enumerate(sorted(self.dic_video_level_preds.keys())):\n",
    "            preds = self.dic_video_level_preds[name]\n",
    "            label = 1.0 if 'FAKE' in name else 0.0\n",
    "                \n",
    "            video_level_preds[i,:] = preds / 100\n",
    "            video_level_labels[i] = label\n",
    "            if np.argmax(preds) == (label):\n",
    "                correct += 1\n",
    "        if self.args.save_predictions:        \n",
    "            np.save(open(f'predictions/{self.args.start_task}_{self.args.task}_labels_{self.args.stream}.npy','wb'), video_level_labels)\n",
    "            np.save(open(f'predictions/{self.args.start_task}_{self.args.task}_preds_{self.args.stream}.npy','wb'), video_level_preds)\n",
    "\n",
    "        video_level_labels = torch.from_numpy(video_level_labels).long()\n",
    "        video_level_preds = torch.from_numpy(video_level_preds).float()\n",
    "            \n",
    "        top1 = accuracy(video_level_preds, video_level_labels, topk=(1,))\n",
    "        loss = self.criterion(video_level_preds, video_level_labels)\n",
    "                                 \n",
    "        logits = nn.functional.softmax(video_level_preds, dim=1)[:, 1].numpy()\n",
    "        auc = roc_auc_score(video_level_labels, logits)\n",
    "        pauc_10 = roc_auc_score(video_level_labels, logits, max_fpr=0.1)\n",
    "        tar_10 = calculate_tpr_10(video_level_labels, logits)\n",
    "        eer = calculate_eer(video_level_labels, logits)\n",
    "        \n",
    "        return top1.item(), auc, loss.item(), pauc_10, tar_10, eer                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FF++ to FF++\n",
      "==> Training data: 972000 frames\n",
      "==> Validation data: 70000 frames\n",
      "==> Testing data: 70000 frames\n",
      "==> Pushing data: 360000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2188 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2188/2188 [12:53<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [773.789], 'Loss': [0.37331], 'Acc': [83.0], 'AUC': [0.9091], 'pAUC_10': [0.8146], 'TAR_10': [0.7946], 'EER': [0.1821]}\n",
      "FF++ to DFD\n",
      "==> Training data: 749969 frames\n",
      "==> Validation data: 24766 frames\n",
      "==> Testing data: 33019 frames\n",
      "==> Pushing data: 281940 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1032 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1032/1032 [06:14<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [374.934], 'Loss': [0.75972], 'Acc': [64.759], 'AUC': [0.7061], 'pAUC_10': [0.5765], 'TAR_10': [0.2602], 'EER': [0.3606]}\n",
      "FF++ to Celeb-DF\n",
      "==> Training data: 1600307 frames\n",
      "==> Validation data: 51740 frames\n",
      "==> Testing data: 51740 frames\n",
      "==> Pushing data: 601000 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1617 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1617/1617 [14:27<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [867.727], 'Loss': [0.70246], 'Acc': [70.0772], 'AUC': [0.7176], 'pAUC_10': [0.5602], 'TAR_10': [0.2794], 'EER': [0.3265]}\n",
      "FF++ to DeeperForensics\n",
      "==> Training data: 2277684 frames\n",
      "==> Validation data: 115200 frames\n",
      "==> Testing data: 241200 frames\n",
      "==> Pushing data: 843600 frames\n",
      "==> Loading pretrained model model/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7538 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--> [testing stage]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7538/7538 [1:15:25<00:00,  2.41it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': [2], 'Time': [4525.527], 'Loss': [0.99517], 'Acc': [58.9967], 'AUC': [0.8452], 'pAUC_10': [0.7096], 'TAR_10': [0.6092], 'EER': [0.2402]}\n"
     ]
    }
   ],
   "source": [
    "for i in ['FF++']:\n",
    "    for j in ['FF++', 'DFD', 'Celeb-DF', 'DeeperForensics']:\n",
    "        print(f'{i} to {j}')\n",
    "\n",
    "        class Args:\n",
    "            gpu = '0,1'\n",
    "            start_task = i\n",
    "            task = j\n",
    "            num_workers = 8\n",
    "            num_epochs = 20\n",
    "            batch_size = 32\n",
    "            learning_rate = 2e-4\n",
    "            stream = 'rgb'\n",
    "            checkpoint = ''\n",
    "            save_predictions = False\n",
    "        args = Args()\n",
    "        \n",
    "        if args.stream =='rgb':\n",
    "            args.checkpoint = f'record/c40/{i}/seed_2/best_val_checkpoint.pth'      \n",
    "        elif args.stream == 'luminance':\n",
    "            args.checkpoint = f'record/luminance/{i}/seed_1/best_val_checkpoint.pth'\n",
    "        elif args.stream == 'sharpened':\n",
    "            args.checkpoint = f'record/sharpened/{i}/seed_1/best_val_checkpoint.pth'\n",
    "\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        log_dir = ''\n",
    "\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "        data_dir = '/meladyfs/newyork/loctrinh/DATASETS/'\n",
    "        frame_count = {f'{j}': pd.read_csv(os.path.join(data_dir, f'{j}', 'video_stat.csv'), index_col=0)}\n",
    "        train_df = pd.read_csv(os.path.join(data_dir, '{}/splits/{}_trainlist_01.csv'.format(j, args.task)))\n",
    "        val_df = pd.read_csv(os.path.join(data_dir, '{}/splits/{}_vallist_01.csv'.format(j, args.task)))\n",
    "        test_df = pd.read_csv(os.path.join(data_dir, '{}/splits/{}_testlist_01.csv'.format(j, args.task)))\n",
    "        \n",
    "        if args.stream == 'rgb':\n",
    "            data_loader = dataloader.StackC40ImageLoader(args.batch_size, args.num_workers, data_dir, frame_count,\n",
    "                                                       train_df, val_df, test_df, train_transform, test_transform)\n",
    "        elif args.stream == 'luminance':\n",
    "            data_loader = dataloader.LuminanceGradientImageLoader(args.batch_size, args.num_workers, data_dir, frame_count,\n",
    "                                                                  train_df, val_df, test_df, train_transform, test_transform)\n",
    "        elif args.stream == 'sharpened':\n",
    "            data_loader = dataloader.SharpenedImageLoader(args.batch_size, args.num_workers, data_dir, frame_count,\n",
    "                                                                  train_df, val_df, test_df, train_transform, test_transform)\n",
    "        \n",
    "        train_loader, val_loader, test_loader, push_loader = data_loader.run()\n",
    "\n",
    "        # =================== Training =================== \n",
    "        detector = DPNet(device=device,\n",
    "                            log_dir=log_dir,\n",
    "                            args=args,\n",
    "                            train_loader=train_loader,\n",
    "                            val_loader=val_loader,\n",
    "                            test_loader=test_loader)\n",
    "        detector.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
